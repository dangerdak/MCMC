\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{metropolis}
\citation{statphys}
\citation{halton}
\citation{som}
\@writefile{toc}{\contentsline {section}{\numberline {1}Background}{2}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Monte Carlo Methods}{2}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Rejection Sampling}{3}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Markov Chains \& The Metropolis-Hastings Algorithm}{3}{subsection.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Univariate Target Distribution}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Analytical Solution}{3}{subsection.2.1}}
\citation{handbook}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Rejection Sampling}{4}{subsection.2.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rejection}{{1a}{4}{The histogram in green represents the distribution found by rejection sampling. The Monte Carlo mean and standard deviation are found to be $\mu _{MC} = 0.463$ and $\mu _{MC} = 0.032$. The blue line is the analytical distribution.\relax }{figure.caption.2}{}}
\newlabel{fig:rejection@cref}{{[subfigure][1][1]1a}{4}}
\newlabel{sub@fig:rejection}{{a}{4}{The histogram in green represents the distribution found by rejection sampling. The Monte Carlo mean and standard deviation are found to be $\mu _{MC} = 0.463$ and $\mu _{MC} = 0.032$. The blue line is the analytical distribution.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:rejection@cref}{{[subfigure][1][1]1a}{4}}
\newlabel{fig:rejlog}{{1b}{4}{A log-plot makes it easier to see the discrepencies at the extremities of the plot. These are due to the finite domain over which samples are taken using this method.\relax }{figure.caption.2}{}}
\newlabel{fig:rejlog@cref}{{[subfigure][2][1]1b}{4}}
\newlabel{sub@fig:rejlog}{{b}{4}{A log-plot makes it easier to see the discrepencies at the extremities of the plot. These are due to the finite domain over which samples are taken using this method.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:rejlog@cref}{{[subfigure][2][1]1b}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax }}{4}{figure.caption.2}}
\newlabel{fig:rejplots}{{1}{4}{\relax }{figure.caption.2}{}}
\newlabel{fig:rejplots@cref}{{[figure][1][]1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Metropolis-Hastings Algorithm}{4}{subsection.2.3}}
\newlabel{fig:metropolis}{{2a}{5}{The histogram in green represents the distribution found by the Metropolis-Hastings algorithm. The Monte Carlo mean and standard deviation are found to be $\mu _{MC} = 0.463$ and $\sigma _{MC} = 0.032$. The blue line is the analytical distribution.\relax }{figure.caption.3}{}}
\newlabel{fig:metropolis@cref}{{[subfigure][1][2]2a}{5}}
\newlabel{sub@fig:metropolis}{{a}{5}{The histogram in green represents the distribution found by the Metropolis-Hastings algorithm. The Monte Carlo mean and standard deviation are found to be $\mu _{MC} = 0.463$ and $\sigma _{MC} = 0.032$. The blue line is the analytical distribution.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:metropolis@cref}{{[subfigure][1][2]2a}{5}}
\newlabel{fig:mhlog}{{2b}{5}{A log-plot of the Metropolis-Hastings results shows that the sample is more consistent with the analytical solution, as compared with figure \ref {fig:rejlog}.\relax }{figure.caption.3}{}}
\newlabel{fig:mhlog@cref}{{[subfigure][2][2]2b}{5}}
\newlabel{sub@fig:mhlog}{{b}{5}{A log-plot of the Metropolis-Hastings results shows that the sample is more consistent with the analytical solution, as compared with figure \ref {fig:rejlog}.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:mhlog@cref}{{[subfigure][2][2]2b}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax }}{5}{figure.caption.3}}
\newlabel{fig:mh}{{2}{5}{\relax }{figure.caption.3}{}}
\newlabel{fig:mh@cref}{{[figure][2][]2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Starting the chain from three very different states gives us an idea of how the chain converges. We see the chains meet after about 200 iterations, suggesting that the chain converges around here.\relax }}{5}{figure.caption.4}}
\newlabel{fig:convergence}{{3}{5}{Starting the chain from three very different states gives us an idea of how the chain converges. We see the chains meet after about 200 iterations, suggesting that the chain converges around here.\relax }{figure.caption.4}{}}
\newlabel{fig:convergence@cref}{{[figure][3][]3}{5}}
\newlabel{fig:metropolisb}{{4a}{6}{The results from the Metropolis-Hastings algorithm with the first 200 iterations removed as burn-in. \relax }{figure.caption.5}{}}
\newlabel{fig:metropolisb@cref}{{[subfigure][1][4]4a}{6}}
\newlabel{sub@fig:metropolisb}{{a}{6}{The results from the Metropolis-Hastings algorithm with the first 200 iterations removed as burn-in. \relax }{figure.caption.5}{}}
\newlabel{sub@fig:metropolisb@cref}{{[subfigure][1][4]4a}{6}}
\newlabel{fig:mhlogb}{{4b}{6}{A log plot of the Metropolis-Hastings results with burn-in removed. Although the plot appears different, $\mu $ remains the same to 3 significant figures, and the standard deviation is also unaffected at this precision.\relax }{figure.caption.5}{}}
\newlabel{fig:mhlogb@cref}{{[subfigure][2][4]4b}{6}}
\newlabel{sub@fig:mhlogb}{{b}{6}{A log plot of the Metropolis-Hastings results with burn-in removed. Although the plot appears different, $\mu $ remains the same to 3 significant figures, and the standard deviation is also unaffected at this precision.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:mhlogb@cref}{{[subfigure][2][4]4b}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax }}{6}{figure.caption.5}}
\newlabel{fig:mhplotsb}{{4}{6}{\relax }{figure.caption.5}{}}
\newlabel{fig:mhplotsb@cref}{{[figure][4][]4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Analytical vs Rejection vs MH}{6}{subsection.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Bivariate Target Distribution}{6}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Analytical Solution}{6}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces In blue are the simulated data with their associated error bars. The green line is the linear model $y = \theta _1 + \theta _2 x$ with the parameters $\theta _1$ and $\theta _2$ found analytically.\relax }}{7}{figure.caption.6}}
\newlabel{fig:model}{{5}{7}{In blue are the simulated data with their associated error bars. The green line is the linear model $y = \theta _1 + \theta _2 x$ with the parameters $\theta _1$ and $\theta _2$ found analytically.\relax }{figure.caption.6}{}}
\newlabel{fig:model@cref}{{[figure][5][]5}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Metropolis-Hastings Algorithm}{7}{subsection.3.2}}
\newlabel{fig:rot}{{6a}{7}{Metropolis-Hastings samples as they appear when transformed. The proposal standard deviations can now be parallel to the axes and easily explore the whole target distribution.\relax }{figure.caption.7}{}}
\newlabel{fig:rot@cref}{{[subfigure][1][6]6a}{7}}
\newlabel{sub@fig:rot}{{a}{7}{Metropolis-Hastings samples as they appear when transformed. The proposal standard deviations can now be parallel to the axes and easily explore the whole target distribution.\relax }{figure.caption.7}{}}
\newlabel{sub@fig:rot@cref}{{[subfigure][1][6]6a}{7}}
\newlabel{fig:unrot}{{6b}{7}{Metropolis-Hastings samples transformed back to an ellipse. Proposal standard deviations are hard to optimise for the distribution in this form. \relax }{figure.caption.7}{}}
\newlabel{fig:unrot@cref}{{[subfigure][2][6]6b}{7}}
\newlabel{sub@fig:unrot}{{b}{7}{Metropolis-Hastings samples transformed back to an ellipse. Proposal standard deviations are hard to optimise for the distribution in this form. \relax }{figure.caption.7}{}}
\newlabel{sub@fig:unrot@cref}{{[subfigure][2][6]6b}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax }}{7}{figure.caption.7}}
\newlabel{fig:rot-unrot}{{6}{7}{\relax }{figure.caption.7}{}}
\newlabel{fig:rot-unrot@cref}{{[figure][6][]6}{7}}
\citation{handbook}
\citation{acceptance}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces On the top right is a plot of Metropolis-Hastings samples, shaded to represent $1-$, $2-$ and $3-\sigma $ confidence regions as approximated numerically. This is overlaid with the analytically calculated confidence regions outlined in blue. Alongside are the one-dimensional marginalized posterior distributions for each parameter.\relax }}{8}{figure.caption.8}}
\newlabel{fig:marginalized}{{7}{8}{On the top right is a plot of Metropolis-Hastings samples, shaded to represent $1-$, $2-$ and $3-\sigma $ confidence regions as approximated numerically. This is overlaid with the analytically calculated confidence regions outlined in blue. Alongside are the one-dimensional marginalized posterior distributions for each parameter.\relax }{figure.caption.8}{}}
\newlabel{fig:marginalized@cref}{{[figure][7][]7}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces As above, the green line is the analytical solution. The dashed black line shows the model found using the Metropolis-Hastings method.\relax }}{9}{figure.caption.9}}
\newlabel{fig:model-mcmc}{{8}{9}{As above, the green line is the analytical solution. The dashed black line shows the model found using the Metropolis-Hastings method.\relax }{figure.caption.9}{}}
\newlabel{fig:model-mcmc@cref}{{[figure][8][]8}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Analytical vs MH}{9}{subsection.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{9}{section.4}}
\newlabel{appendix}{{4}{9}{Conclusion}{section.4}{}}
\newlabel{appendix@cref}{{[section][4][]4}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {A}One-Dimensional Likelihood Function}{9}{appendix.A}}
\newlabel{sec:likelihood}{{A}{9}{One-Dimensional Likelihood Function}{appendix.A}{}}
\newlabel{sec:likelihood@cref}{{[appendix][1][2147483647]A}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Computing the Posterior Probability for Theta}{10}{appendix.B}}
\newlabel{sec:posterior}{{B}{10}{Computing the Posterior Probability for Theta}{appendix.B}{}}
\newlabel{sec:posterior@cref}{{[appendix][2][2147483647]B}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Asymptotic Independence of Posterior on Prior}{11}{appendix.C}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Asymptotic Convergence of the Posterior Mean to the MLE Mean for Theta}{11}{appendix.D}}
\@writefile{toc}{\contentsline {section}{\numberline {E}2-D Likelihood in Gaussian Form}{12}{appendix.E}}
\newlabel{sec:2dlikelihood}{{E}{12}{2-D Likelihood in Gaussian Form}{appendix.E}{}}
\newlabel{sec:2dlikelihood@cref}{{[appendix][5][2147483647]E}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {F}2-D Posterior in Gaussian Form}{12}{appendix.F}}
\newlabel{sec:2dposterior}{{F}{12}{2-D Posterior in Gaussian Form}{appendix.F}{}}
\newlabel{sec:2dposterior@cref}{{[appendix][6][2147483647]F}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {G}Data}{13}{appendix.G}}
\newlabel{sec:data}{{G}{13}{Data}{appendix.G}{}}
\newlabel{sec:data@cref}{{[appendix][7][2147483647]G}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {H}Python Code for Univariate Model}{14}{appendix.H}}
\newlabel{sec:onedcode}{{H}{14}{Python Code for Univariate Model}{appendix.H}{}}
\newlabel{sec:onedcode@cref}{{[appendix][8][2147483647]H}{14}}
\@writefile{lol}{\contentsline {lstlisting}{one\textunderscore d.py}{14}{lstlisting.-1}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Python Code for Bivariate Model}{22}{appendix.I}}
\newlabel{sec:twodcode}{{I}{22}{Python Code for Bivariate Model}{appendix.I}{}}
\newlabel{sec:twodcode@cref}{{[appendix][9][2147483647]I}{22}}
\@writefile{lol}{\contentsline {lstlisting}{multivariate.py}{22}{lstlisting.-2}}
\bibcite{metropolis}{1}
\bibcite{statphys}{2}
\bibcite{halton}{3}
\bibcite{som}{4}
\bibcite{inpractice}{5}
\bibcite{acceptance}{6}
\bibcite{handbook}{7}
